{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff06cf5a-9858-42f5-b9b2-611b7215b34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up WebDriver...\n",
      "Attempting to fetch URL: https://www.wsj.com/market-data/stocks/us\n",
      "Waiting up to 20 seconds for content to load...\n",
      "Content with 'Issues At New Highs' seems to have loaded.\n",
      "Attempting to extract data for: New Highs (aria-label='Issues At New Highs')\n",
      "  Successfully extracted: {'value1': '48', 'value2': '70'}\n",
      "Attempting to extract data for: New Lows (aria-label='Issues At New Lows')\n",
      "  Successfully extracted: {'value1': '47', 'value2': '111'}\n",
      "Attempting to extract data for: Advancing Issues (aria-label='Issues Advancing')\n",
      "  Successfully extracted: {'value1': '1225', 'value2': '1823'}\n",
      "Attempting to extract data for: Declining Issues (aria-label='Issues Declining')\n",
      "  Successfully extracted: {'value1': '1537', 'value2': '2671'}\n",
      "Browser closed.\n",
      "\n",
      "--- Extracted Data ---\n",
      "New Highs: Value 1 = 48, Value 2 = 70\n",
      "New Lows: Value 1 = 47, Value 2 = 111\n",
      "Advancing Issues: Value 1 = 1225, Value 2 = 1823\n",
      "Declining Issues: Value 1 = 1537, Value 2 = 2671\n",
      "Error during JSON serialization: name 'output_filename' is not defined\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager # 自动化下载 chromedriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# 设置 Chrome 选项 (可选，但建议用于无头模式等)\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless') # 在后台运行，不打开浏览器窗口。调试时可以注释掉这行。\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\")\n",
    "\n",
    "\n",
    "# 使用 WebDriverManager 自动处理 chromedriver\n",
    "driver = None # 初始化 driver 为 None，用于 finally 块\n",
    "data = {}\n",
    "\n",
    "# Helper function to extract data from a row (辅助函数：从行中提取数据)\n",
    "def extract_row_data(soup_obj, aria_label_value):\n",
    "    \"\"\"\n",
    "    根据 aria-label 查找对应的行，并提取 value1 和 value2。\n",
    "    移除数字中的逗号。\n",
    "    \"\"\"\n",
    "    label_cell = soup_obj.find('td', attrs={'aria-label': aria_label_value})\n",
    "    if label_cell:\n",
    "        row = label_cell.find_parent('tr')\n",
    "        if row:\n",
    "            cells = row.find_all('td')\n",
    "            # 确保至少有3个 td (标签, 值1, 值2)\n",
    "            if len(cells) >= 3:\n",
    "                # 获取文本并移除可能的逗号和空格\n",
    "                val1 = cells[1].get_text(strip=True).replace(',', '')\n",
    "                val2 = cells[2].get_text(strip=True).replace(',', '')\n",
    "                return {'value1': val1, 'value2': val2}\n",
    "    return None # 如果未找到或解析失败，返回 None\n",
    "\n",
    "# 定义需要抓取的项目及其对应的 aria-label\n",
    "items_to_scrape = {\n",
    "    \"New Highs\": \"Issues At New Highs\",\n",
    "    \"New Lows\": \"Issues At New Lows\",\n",
    "    \"Advancing Issues\": \"Issues Advancing\",   # 新增\n",
    "    \"Declining Issues\": \"Issues Declining\" # 新增\n",
    "}\n",
    "\n",
    "try:\n",
    "    print(\"Setting up WebDriver...\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "    url = \"https://www.wsj.com/market-data/stocks/us\"\n",
    "    print(f\"Attempting to fetch URL: {url}\")\n",
    "    driver.get(url)\n",
    "\n",
    "    wait_time = 20 # 秒\n",
    "    print(f\"Waiting up to {wait_time} seconds for content to load...\")\n",
    "\n",
    "    # --- 潜在步骤: 关闭 cookie 横幅 (如果出现) ---\n",
    "    # 请根据实际情况调整或取消这部分代码\n",
    "    # try:\n",
    "    #     # 尝试查找并点击接受 cookie 的按钮。WSJ 的 ID 可能是 'onetrust-accept-btn-handler'\n",
    "    #     cookie_button_id = 'onetrust-accept-btn-handler'\n",
    "    #     cookie_button = WebDriverWait(driver, 10).until(\n",
    "    #         EC.element_to_be_clickable((By.ID, cookie_button_id))\n",
    "    #     )\n",
    "    #     cookie_button.click()\n",
    "    #     print(\"Cookie banner clicked (assumed accept).\")\n",
    "    #     time.sleep(2) # 等待页面响应\n",
    "    # except Exception as e:\n",
    "    #     print(f\"No cookie banner found or could not click: {e}\")\n",
    "    # --- 结束潜在步骤 ---\n",
    "\n",
    "\n",
    "    # 等待页面上的关键元素出现。我们等待 \"New Highs\" 标签出现，这表明相关的表格数据已加载。\n",
    "    key_element_aria_label = \"Issues At New Highs\"\n",
    "    key_element_xpath = f\"//td[@aria-label='{key_element_aria_label}']\"\n",
    "\n",
    "    WebDriverWait(driver, wait_time).until(\n",
    "        EC.presence_of_element_located((By.XPATH, key_element_xpath))\n",
    "    )\n",
    "    print(f\"Content with '{key_element_aria_label}' seems to have loaded.\")\n",
    "\n",
    "    # 获取 JavaScript 执行后的页面源代码\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    # 遍历定义的项目并抓取数据\n",
    "    for display_name, aria_label in items_to_scrape.items():\n",
    "        print(f\"Attempting to extract data for: {display_name} (aria-label='{aria_label}')\")\n",
    "        row_data = extract_row_data(soup, aria_label)\n",
    "        if row_data:\n",
    "            data[display_name] = row_data\n",
    "            print(f\"  Successfully extracted: {row_data}\")\n",
    "        else:\n",
    "            print(f\"  Warning: Could not find or parse data for '{display_name}' (aria-label: '{aria_label}')\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during scraping: {e}\")\n",
    "    # 如果出错，可以保存页面源码以便调试\n",
    "    # if driver:\n",
    "    #     with open(\"wsj_error_page_combined.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    #         f.write(driver.page_source)\n",
    "    #     print(\"Saved error page source to wsj_error_page_combined.html\")\n",
    "\n",
    "finally:\n",
    "    # 确保浏览器在任何情况下都被关闭\n",
    "    if driver:\n",
    "        driver.quit()\n",
    "        print(\"Browser closed.\")\n",
    "\n",
    "print(\"\\n--- Extracted Data ---\")\n",
    "output_filename=\"wsj_data.txt\"\n",
    "if data:\n",
    "    for key, values in data.items():\n",
    "        print(f\"{key}: Value 1 = {values['value1']}, Value 2 = {values['value2']}\")\n",
    "\n",
    "    # --- 将数据保存到 TXT 文件 (JSON 格式) ---\n",
    "    try:\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f_out:\n",
    "            json.dump(data, f_out, indent=4, ensure_ascii=False) # indent 使 JSON 文件更易读\n",
    "        print(f\"\\nData successfully saved to {output_filename}\")\n",
    "    except IOError as e_io:\n",
    "        print(f\"Error saving data to file {output_filename}: {e_io}\")\n",
    "    except Exception as e_json:\n",
    "        print(f\"Error during JSON serialization: {e_json}\")\n",
    "    # --- 保存结束 ---\n",
    "else:\n",
    "    print(\"No data was extracted. Nothing to save to file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5717f8fe-56b1-4176-8ba9-a7f56039784b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.5 (mypython312)",
   "language": "python",
   "name": "mypython312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
